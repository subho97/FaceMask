{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading all the required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import *\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will using the ImageDataGenerator from keras package to load all our image files directly from the directory on our local machine. \n",
    "\n",
    "#### The first block contains the path files where your dataset folder should be located. Here, in the example the mask folder contains the sub folder train, test and val. Inside each sub-folder there are two more folders called \"Mask\" and \"No Mask\". Each folder has a certain number of image files(.jpg)\n",
    "\n",
    "#### The ImageDataGenerator function helps us to directly import the image files(.jpg) from our directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example code:\n",
    "\n",
    "train_path = 'C:\\\\mask\\\\train'\n",
    "test_path  = 'C:\\\\mask\\\\test'\n",
    "val_path   = 'C:\\\\mask\\\\val'\n",
    "\n",
    "'''\n",
    "\n",
    "train_path = 'C:\\\\mask\\\\train'\n",
    "test_path  = 'C:\\\\mask\\\\test'\n",
    "val_path   = 'C:\\\\mask\\\\val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following lines of code load our image files(.jpg) into three different tensor DataIterator namely:\n",
    "#### 1. train_batches = containing all the train images and their labels.\n",
    "#### 2. val_batches = containing all the validation images and their labels.\n",
    "#### 2. train_batches = containing all the test images and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches  = ImageDataGenerator(preprocessing_function = keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    train_path, target_size=(224,224), classes=['0 (Mask Off)', '1 (Mask On)'], shuffle = True, batch_size=10)\n",
    "\n",
    "val_batches  = ImageDataGenerator(preprocessing_function = keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    val_path, target_size=(224,224), classes=['0 (Mask Off)', '1 (Mask On)'], shuffle = True, batch_size=10)\n",
    "\n",
    "test_batches  = ImageDataGenerator(preprocessing_function = keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
    "    test_path, target_size=(224,224), classes=['0 (Mask Off)', '1 (Mask On)'], shuffle = True, batch_size=194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = next(test_batches) #This helps us to extract all the test image files and their labels \n",
    "                                    #into two different varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Test Examples:\", x_test.shape[0])\n",
    "print(\"Number of unique values of Y:\", y_test.shape[1])\n",
    "print(\"Size of Each image:\", x_test.shape[1], \"*\", x_test.shape[2], \"* 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pre-trained MobileNetV2 CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "model.summary() #Prints the model summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Plots a Visual Map of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model looks good but it needs to be tuned to be able to detect human faces and should able to differentiate between people wearning face masks and people not wearning face masks\n",
    "\n",
    "#### The original Network contains an ReLu activation layer as out put which needs to be replaced with a softamac function of two classes for our binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.output                               #Removes the output layer from the original Model\n",
    "x = AveragePooling2D(pool_size=(7, 7))(x)      #Adds an AveragePooling Layer of size 7*7\n",
    "x = Flatten(name=\"flatten\")(x)                 #Flatten the Image\n",
    "x = Dense(128, activation=\"relu\")(x)           #Apply a ReLu activation function\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2, activation=\"softmax\")(x)          #Apply a softmax function of 2 classes for binary classification\n",
    "\n",
    "model = Model(inputs = model.input, outputs = x)  #Using Keras Model Object to create the Modified Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the graph of the Modified Neural Network\n",
    "\n",
    "#### You can compare the graph of this model with the earlier plotted graph and observe the changes in the total number of layers and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Optimizing Paramteres\n",
    "\n",
    "#### After multiple iterations the following optimizing parameters seem to work pretty well in helping our model achieve a higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=1e-4, decay=1e-4 / 20)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traning the model and passing the validation batches to test the train and validation accuracy\n",
    "\n",
    "#### The moedl.fit function from Keras helps us to do this.\n",
    "\n",
    "#### Depending on our computer specifications this might take some time. On my system it takes around 30 mins.\n",
    "\n",
    "#### So, untill the model gets trained you can get yourself some coffee. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_batches, batch_size = 32, steps_per_epoch= 18 , validation_data=(val_batches), validation_steps= 2, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's time to evaluate our model by running it on your Test Set\n",
    "\n",
    "#### The evaluate fucntion helps to pass the x_test containg the test images and the y_test containing the labels. The batch size is equal to the total number of images in the test set which means that the model will be run on all the images in test set at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  \n",
    "preds = model.evaluate(x=x_test, y=y_test, batch_size=194)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With an accuracy of 99.48% on your test set we can say that our model is doing very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is very imortant to save our model once the model is trained. The saved model will contain the weights that thus eliminate the need to retrain the model again whenever we want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('mask_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_model = load_model('mask_model.h5') #model = load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Model is doing pretty good. Let's test it on some local, new Images.\n",
    "\n",
    "### Why not tot est it out on your own image ?\n",
    "### Set the Path to your Image in img_path variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example Code :\n",
    "\n",
    "img_path = 'C:/Users/My_picture.jpg'\n",
    "\n",
    "'''\n",
    "\n",
    "img_path = 'PATH'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "imshow(img)\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "if (model.predict(x).argmax(axis=1)) == 0:\n",
    "    print(\"Mask Off\")\n",
    "else:\n",
    "    print(\"Mask On\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THANK YOU FOR READING !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you want to know how you can implement this model to classify live video stream, do check out the other files in the repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
